# tools/ui_copilot.py
from __future__ import annotations
import io, json, os, traceback
from pathlib import Path

import pandas as pd
import streamlit as st

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from app.io.loader import load_table, write_table, detect_encoding
from app.core.profile import profile_dataframe
from app.excel_ops.clean import level1_clean
from app.excel_ops.dedupe import dedupe
from app.excel_ops.impute import impute as do_impute
from app.excel_ops.outlier import outlier as do_outlier
from app.validate.dsl import validate as dsl_validate
from app.autoexcel.intent import parse as nl_parse

# ì„ íƒì : Fallback/COM ì—”ì§„ ë¡œë“œ
try:
    from app.autoexcel.engines_fallback import create_pivot_from_df, add_chart
except Exception:  # pragma: no cover
    create_pivot_from_df = add_chart = None

try:
    from app.autoexcel.engines_com import create_pivot_chart
    HAS_COM = True
except Exception:
    HAS_COM = False

st.set_page_config(page_title="Smart Excel Copilot", layout="wide")
st.markdown(
    """
    <style>
      .badge-ok{background:#16a34a;color:#fff;padding:2px 8px;border-radius:999px}
      .badge-warn{background:#d97706;color:#fff;padding:2px 8px;border-radius:999px}
      .muted{color:#64748b}
    </style>
    """,
    unsafe_allow_html=True,
)

# ---------------------------
# ê³µìš© ìœ í‹¸
# ---------------------------
def _load_df(path: str|None, upload) -> tuple[pd.DataFrame, dict]:
    if upload is not None:
        # ì—…ë¡œë“œ íŒŒì¼ ë©”ëª¨ë¦¬ì— ì €ì¥ í›„ ë¡œë”ë¡œ ì „ë‹¬
        tmp = Path("data/_uploads"); tmp.mkdir(parents=True, exist_ok=True)
        p = tmp / upload.name
        p.write_bytes(upload.getbuffer())
        enc = detect_encoding(str(p))
        df, meta = load_table(str(p), encoding=enc.get("encoding"))
        meta["path"] = str(p)
        return df, meta
    if path:
        enc = detect_encoding(path)
        df, meta = load_table(path, encoding=enc.get("encoding"))
        meta["path"] = path
        return df, meta
    raise ValueError("íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

def _download_df_button(df: pd.DataFrame, filename: str, label="CSV ë‹¤ìš´ë¡œë“œ"):
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(label, data=buf.getvalue(), file_name=filename, mime="text/csv")

def _save_xlsx_and_download(df: pd.DataFrame, path: str, sheet="ì •ë¦¬ë³¸"):
    Path(path).parent.mkdir(parents=True, exist_ok=True)
    write_table(df, path, sheet=sheet)
    with open(path, "rb") as f:
        st.download_button("ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", f.read(), file_name=Path(path).name, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

def _pretty_json(obj):
    st.code(json.dumps(obj, ensure_ascii=False, indent=2), language="json")

# ---------------------------
# ì‚¬ì´ë“œë°”: ì…ë ¥ ì†ŒìŠ¤
# ---------------------------
with st.sidebar:
    st.header("ğŸ“‚ ì…ë ¥")
    path = st.text_input("íŒŒì¼ ê²½ë¡œ(.csv/.xlsx)", value="data/goldensets/s01_mixed_currency.csv")
    upload = st.file_uploader("ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ", type=["csv","xlsx"])
    st.caption("ê²½ë¡œ ë˜ëŠ” ì—…ë¡œë“œ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")
    st.divider()
    st.header("âš™ï¸ ì„¤ì •")
    parser = st.selectbox("ìì—°ì–´ íŒŒì„œ", ["auto","rule","llm"], index=0)
    engine = st.selectbox("ì—‘ì…€ ì—”ì§„", ["fallback","com" if HAS_COM else "fallback"], index=0)
    st.caption(f"COM ì—”ì§„ ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if HAS_COM else 'ì•„ë‹ˆì˜¤'}")

# ---------------------------
# íƒ­
# ---------------------------
tab_pro, tab_pre, tab_auto, tab_val, tab_log, tab_watch = st.tabs(
    ["ğŸ” í”„ë¡œíŒŒì¼ë§", "ğŸ§¹ ì „ì²˜ë¦¬", "ğŸ“Š ì—‘ì…€ ìë™í™”", "âœ… ê²€ì¦", "ğŸ“œ ë¡œê·¸/ë¦¬í¬íŠ¸", "ğŸ‘ï¸ í´ë” ê°ì‹œ"]
)

# ---------------------------
# í”„ë¡œíŒŒì¼ë§
# ---------------------------
with tab_pro:
    st.subheader("ğŸ” ë°ì´í„° í”„ë¡œíŒŒì¼ë§")
    if st.button("í”„ë¡œíŒŒì¼ ìƒì„±"):
        try:
            df, meta = _load_df(path, upload)
            prof = profile_dataframe(df)
            st.success("í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ")
            st.write(f"í–‰/ì—´: **{len(df)} x {df.shape[1]}**")
            cols = prof.get("columns", [])
            for c in cols:
                with st.expander(f"ì—´: {c.get('name')}"):
                    _pretty_json(c)
            with st.expander("ì „ì²´ í”„ë¡œíŒŒì¼ JSON"):
                _pretty_json(prof)
            st.session_state["last_df"] = df
            st.session_state["last_meta"] = meta
        except Exception as e:
            st.error(str(e))
            st.exception(e)

# ---------------------------
# ì „ì²˜ë¦¬
# ---------------------------
with tab_pre:
    st.subheader("ğŸ§¹ ì „ì²˜ë¦¬ (Level1 + Dedupe/Impute/Outlier)")
    c1, c2, c3, c4 = st.columns(4)
    with c1: opt_trim = st.checkbox("íŠ¸ë¦¼/ê³µë°± ì •ë¦¬", True)
    with c2: opt_currency = st.checkbox("í†µí™” ë¶„ë¦¬+ìˆ«ìí™”", True)
    with c3: opt_date = st.checkbox("ë‚ ì§œ ISO(YYYY-MM-DD)", True)
    with c4: opt_drop_empty = st.checkbox("ë¹ˆ í–‰/ì—´ ì œê±°", True)

    st.markdown("**ì¤‘ë³µ ì œê±°**")
    c5, c6 = st.columns(2)
    with c5: dedupe_keys = st.text_input("í‚¤(ì‰¼í‘œë¡œ êµ¬ë¶„, ë¹„ìš°ë©´ ì „ì²´ ì—´ ë¹„êµ)", value="ê±°ë˜ID")
    with c6: keep_rule = st.text_input("ë³´ì¡´ ì •ì±…(first/last/last_by:ì—…ë°ì´íŠ¸ì¼)", value="last")

    st.markdown("**ê²°ì¸¡/ì´ìƒì¹˜**")
    impute_rule = st.text_input('ê²°ì¸¡ ê·œì¹™ ì˜ˆ: `median:ê¸ˆì•¡;zero:ìˆ˜ëŸ‰`', value="")
    outlier_rule = st.text_input('ì´ìƒì¹˜ ê·œì¹™ ì˜ˆ: `iqr_clip:ê¸ˆì•¡@k=1.5`', value="")

    st.markdown("**ê²Œì´íŠ¸ DSL (ì €ì¥ ì°¨ë‹¨ ì¡°ê±´)**")
    c7, c8 = st.columns(2)
    with c7: gate_path = st.text_input("DSL íŒŒì¼ ê²½ë¡œ(YAML/JSON, ì„ íƒ)", value="")
    with c8: gate_threshold = st.slider("í†µê³¼ìœ¨ ì„ê³„ê°’", 0.0, 1.0, 1.0, 0.05)

    if st.button("ë¯¸ë¦¬ë³´ê¸°"):
        try:
            df, meta = _load_df(path, upload)
            df1 = level1_clean(df, trim=opt_trim, date_fmt=("YYYY-MM-DD" if opt_date else "KEEP"),
                               currency_split=opt_currency, drop_empty=opt_drop_empty)
            info = {}
            # dedupe
            if dedupe_keys.strip():
                keys = [k.strip() for k in dedupe_keys.split(",") if k.strip()]
                df1, info = dedupe(df1, keys=keys, keep=keep_rule)
            # impute
            if impute_rule.strip():
                def parse_kv(s):
                    out=[]
                    for t in s.split(";"):
                        t=t.strip()
                        if not t: continue
                        m,c = t.split(":",1)
                        out.append({"method":m.strip(),"col":c.strip()})
                    return out
                df1, rep_i = do_impute(df1, parse_kv(impute_rule))
                st.caption(f"ê²°ì¸¡ ëŒ€ì²´ ë¦¬í¬íŠ¸: {json.dumps(rep_i, ensure_ascii=False)}")
            # outlier
            if outlier_rule.strip():
                def parse_ol(s):
                    out=[]
                    for t in s.split(";"):
                        t=t.strip()
                        if not t: continue
                        head,*attrs = t.split("@")
                        m,c = head.split(":",1)
                        item={"method":m.strip(),"col":c.strip()}
                        for a in attrs:
                            for kv in a.split(","):
                                if "=" in kv:
                                    k,v = kv.split("=",1)
                                    try: v = float(v) if any(x in v for x in ".0123456789") else v
                                    except: pass
                                    item[k.strip()]=v
                        out.append(item)
                    return out
                df1, rep_o = do_outlier(df1, parse_ol(outlier_rule))
                st.caption(f"ì´ìƒì¹˜ ì²˜ë¦¬ ë¦¬í¬íŠ¸: {json.dumps(rep_o, ensure_ascii=False)}")

            st.success("ì „ì²˜ë¦¬ ë¯¸ë¦¬ë³´ê¸° ì™„ë£Œ")
            st.dataframe(df1.head(30))
            st.session_state["preview_df"] = df1
            st.session_state["preview_meta"] = meta
            if info:
                st.caption(f"ì¤‘ë³µ ì œê±° ìš”ì•½: {json.dumps(info, ensure_ascii=False)}")
        except Exception as e:
            st.error("ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            st.exception(e)

    if "preview_df" in st.session_state and st.button("ì €ì¥(ê²Œì´íŠ¸ ê²€ì‚¬ í¬í•¨)"):
        try:
            df1 = st.session_state["preview_df"]
            # ê²Œì´íŠ¸ ê²€ì‚¬
            if gate_path.strip():
                with open(gate_path, "r", encoding="utf-8") as f:
                    import yaml
                    spec = yaml.safe_load(f)
                rep = dsl_validate(df1, spec)
                details = rep.get("details", [])
                pass_ratio = (sum(1 for d in details if d.get("ok")) / max(1, len(details)))
                st.caption(f"ê²Œì´íŠ¸ ê²°ê³¼: pass_ratio={pass_ratio:.3f}")
                _pretty_json(rep)
                if pass_ratio < float(gate_threshold):
                    st.error(f"í†µê³¼ìœ¨ {pass_ratio:.3f} < ì„ê³„ê°’ {gate_threshold} â†’ ì €ì¥ ì°¨ë‹¨")
                    st.stop()

            # ì €ì¥
            out_path = "data/out/ui_cleaned.xlsx"
            _save_xlsx_and_download(df1, out_path)
            st.success(f"ì €ì¥ ì™„ë£Œ: {out_path}")
        except Exception as e:
            st.error("ì €ì¥ ì‹¤íŒ¨")
            st.exception(e)

# ---------------------------
# ì—‘ì…€ ìë™í™” (ìì—°ì–´)
# ---------------------------
with tab_auto:
    st.subheader("ğŸ“Š ìì—°ì–´ â†’ í”¼ë²—/ì°¨íŠ¸")
    ask = st.text_input("ìš”ì²­", value="ì›”ë³„ ì¹´í…Œê³ ë¦¬ ë§¤ì¶œ í”¼ë²— ë§Œë“¤ê³  ë§‰ëŒ€ì°¨íŠ¸, ì§€ì—­ì€ ì„œìš¸ê³¼ ë¶€ì‚°ë§Œ")
    out_xlsx = st.text_input("ì¶œë ¥ ê²½ë¡œ", value="data/automation/auto_out.xlsx")
    
    # MoM/YTD ì˜µì…˜ ì¶”ê°€
    add_mom_ytd = st.checkbox("MoM(ì „ì›”ëŒ€ë¹„) + YTD(ëˆ„ê³„) ì—´ ìë™ ì¶”ê°€", True)
    
    if st.button("ìƒì„±"):
        try:
            df, meta = _load_df(path, upload)
            intent = nl_parse(ask, columns=df.columns, parser=parser)
            st.caption(f"ì˜ë„: {intent.model_dump() if hasattr(intent,'model_dump') else intent.__dict__}")
            Path(out_xlsx).parent.mkdir(parents=True, exist_ok=True)

            if engine == "com" and HAS_COM:
                # ì›ë³¸ì„ xlsxë¡œ ë³´ì¥
                tmp_src = "data/automation/_tmp_src.xlsx"
                write_table(df, tmp_src, sheet="ì›ë³¸")
                rows = intent.rows or ["ì›”","ì¹´í…Œê³ ë¦¬"]
                vals = intent.values or [("ê¸ˆì•¡","sum")]
                create_pivot_chart(tmp_src, out_xlsx, "ì›ë³¸", "í”¼ë²—_ê²°ê³¼", rows, vals, chart_type=intent.chart or "bar")
            else:
                rows = intent.rows or ["ì›”","ì¹´í…Œê³ ë¦¬"]
                vals = intent.values or [("ê¸ˆì•¡","sum")]
                filters = getattr(intent, "filters", None)
                shape = create_pivot_from_df(df, out_xlsx, "03_í”¼ë²—", rows, vals, filters=filters)
                if intent.chart:
                    add_chart(out_xlsx, "03_í”¼ë²—", title="ìë™ ì°¨íŠ¸", chart_type=intent.chart)
                st.caption(f"í”¼ë²— shape: {shape}")

            # MoM/YTD ì—´ ì¶”ê°€
            if add_mom_ytd:
                try:
                    from app.autoexcel.formulas import add_mom_ytd_columns
                    add_mom_ytd_columns(out_xlsx, "03_í”¼ë²—")
                    st.success("âœ… MoM/YTD ì—´ ì¶”ê°€ ì™„ë£Œ")
                except Exception as e:
                    st.warning(f"âš ï¸ MoM/YTD ì—´ ì¶”ê°€ ì‹¤íŒ¨: {e}")

            st.success(f"ì™„ë£Œ: {out_xlsx}")
            with open(out_xlsx, "rb") as f:
                st.download_button("ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", f.read(), file_name=Path(out_xlsx).name)
        except Exception as e:
            st.error("ì—‘ì…€ ìë™í™” ì‹¤íŒ¨")
            st.exception(e)

# ---------------------------
# ê²€ì¦ DSL
# ---------------------------
with tab_val:
    st.subheader("âœ… ê²€ì¦(DSL)")
    dsl_path = st.text_input("DSL ê²½ë¡œ(YAML/JSON)", value="examples/validation_example.yaml")
    if st.button("ê²€ì¦ ì‹¤í–‰"):
        try:
            df, meta = _load_df(path, upload)
            import yaml
            spec = yaml.safe_load(open(dsl_path, "r", encoding="utf-8"))
            rep = dsl_validate(df, spec)
            _pretty_json(rep)
            ok = rep.get("summary",{}).get("ok", False)
            badge = '<span class="badge-ok">PASS</span>' if ok else '<span class="badge-warn">FAIL</span>'
            st.markdown(f"ê²°ê³¼: {badge}", unsafe_allow_html=True)
        except Exception as e:
            st.error("ê²€ì¦ ì‹¤íŒ¨")
            st.exception(e)

# ---------------------------
# ë¡œê·¸/ë¦¬í¬íŠ¸
# ---------------------------
with tab_log:
    st.subheader("ğŸ“œ ë¡œê·¸/ë¦¬í¬íŠ¸")
    # KPI ìµœê·¼ ê²°ê³¼ í‘œì‹œ(ìˆë‹¤ë©´)
    kpi = Path("logs/kpi_last.json")
    if kpi.exists():
        st.markdown("**ìµœê·¼ KPI**")
        st.code(kpi.read_text(encoding="utf-8"), language="json")
        st.download_button("KPI JSON ë‹¤ìš´ë¡œë“œ", data=kpi.read_bytes(), file_name=kpi.name)
    else:
        st.caption("KPI ë¡œê·¸ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. tools/eval_kpi.pyë¥¼ ì‹¤í–‰í•´ ë³´ì„¸ìš”.")
    # ìµœê·¼ ê³¨ë“ ì…‹ ìš”ì•½
    gdir = Path("logs/golden_runs")
    if gdir.exists():
        latest = sorted(gdir.glob("golden_*.json"))[-1:]
        for p in latest:
            st.markdown("**ìµœê·¼ ê³¨ë“ ì…‹ ê²°ê³¼**")
            st.code(p.read_text(encoding="utf-8"), language="json")
            st.download_button("ê³¨ë“ ì…‹ ìš”ì•½ ë‹¤ìš´ë¡œë“œ", data=p.read_bytes(), file_name=p.name)

# ---------------------------
# í´ë” ê°ì‹œ (Watch)
# ---------------------------
with tab_watch:
    st.subheader("ğŸ‘ï¸ í´ë” ê°ì‹œ â†’ ìë™ ë³´ê³ ì„œ ìƒì„±")
    
    watch_dir = st.text_input("ê°ì‹œí•  í´ë”", value="data/incoming")
    st.caption("CSV/XLSX íŒŒì¼ì´ ì´ í´ë”ì— ë–¨ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ë³´ê³ ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    
    if st.button("ê°ì‹œ ì‹œì‘"):
        try:
            # í´ë” ìƒì„±
            Path(watch_dir).mkdir(parents=True, exist_ok=True)
            
            # ê°ì‹œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
            import subprocess
            cmd = [sys.executable, "tools/watch_run.py", "--dir", watch_dir]
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            
            st.success(f"í´ë” ê°ì‹œ ì‹œì‘: {watch_dir}")
            st.info("ì´ì œ í´ë”ì— CSV/XLSX íŒŒì¼ì„ ë“œë¡­í•˜ë©´ ìë™ìœ¼ë¡œ ë³´ê³ ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
            
            # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í‘œì‹œ
            if process.poll() is None:
                st.caption("âœ… ê°ì‹œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘")
            else:
                st.caption("âŒ ê°ì‹œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
                
        except Exception as e:
            st.error(f"ê°ì‹œ ì‹œì‘ ì‹¤íŒ¨: {e}")
            st.exception(e)
    
    # ê°ì‹œ ì¤‘ì¸ í´ë” ë‚´ìš© í‘œì‹œ
    if Path(watch_dir).exists():
        st.markdown("**ê°ì‹œ í´ë” ë‚´ìš©**")
        files = list(Path(watch_dir).glob("*"))
        if files:
            for f in files:
                st.write(f"ğŸ“„ {f.name} ({f.stat().st_size} bytes)")
        else:
            st.caption("í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. CSV/XLSX íŒŒì¼ì„ ë“œë¡­í•´ë³´ì„¸ìš”.")
    
    # ìë™ ìƒì„±ëœ ë³´ê³ ì„œ ëª©ë¡
    report_dir = Path("data/report")
    if report_dir.exists():
        st.markdown("**ìë™ ìƒì„±ëœ ë³´ê³ ì„œ**")
        auto_reports = list(report_dir.glob("auto_*.xlsx"))
        if auto_reports:
            for r in auto_reports:
                st.write(f"ğŸ“Š {r.name} ({r.stat().st_size} bytes)")
                with open(r, "rb") as f:
                    st.download_button(f"ë‹¤ìš´ë¡œë“œ {r.name}", f.read(), file_name=r.name)
        else:
            st.caption("ì•„ì§ ìë™ ìƒì„±ëœ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

